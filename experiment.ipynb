{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUST TOKENIZER THINGS\n",
    "\n",
    "import logging\n",
    "from hancleaner import ChineseTextCleaner\n",
    "from hancleaner import ChineseTokenizer\n",
    "logging.basicConfig(\n",
    "    filename='logs/chinese/dhloader.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "text_samples = '''\n",
    "卍招财带什么佛牌卍(www.suzastampin.com)卡尔・斯利姆于2012年加入塔塔汽车公司担任总经理一职，并负责公司在印度及国际市场上除捷豹和路虎以外的业务。这位斯坦福大学的毕业生，曾任通用汽车在中国合资公司的。近日，编辑专门联系到山西传奇北京现代汽车4S店得知，店内朗动车型有现车供应，现阶段购车可享受最高6000元优惠幅度，具体的车型和价格情况请见下表，同时感兴趣的朋友还可致电4008112233转3456详询：\n",
    "一个类似美国大片《幸福终点站》的案例令中国驻圣彼得堡领事官胡滨印象深刻。由于行前未能仔细核对签证有效期，一对赴俄罗斯旅游的中国夫妇因为签证过期差点被困在俄罗斯。在胡滨的协助下，这对夫妇经历了惊心动魄的３小时，终于在飞机起飞前５分钟，登上返程的航班。\n",
    "招财带什么佛牌张德江在致辞中表示，中法建交开启了中法两个伟大国家友好关系的新纪元，树立了不同社会制度国家和平共处的新典范，对国际战略格局产生了重大而深远的影响。\n",
    "招财带什么佛牌科斯格罗夫一直供职于军队，曾被派往马来西亚、越南、英国、印度、美国工作。1999年，他成为联合国驻东帝汶部队司令，监督东帝汶向独立国家的过渡。\n",
    "1月28日电据香港《明报》消息，在庆祝披头士进军美国音乐市场50周年的纪念日子，格莱美向两名仅存成员：保罗麦卡尼及灵高史达(RingoStarr)颁发终身成就奖，显得别具意义。为了隆重其事，大会请来金像影后茱莉亚••罗伯茨(JuliaRoberts)负责介绍二人出场，保罗在拍档的鼓声和应下，先献唱新歌《QueenieEye》，然后轮到后者演绎旧作《Photograph》，带领歌迷重温昔日的美好情怀。\n",
    "佛牌绳哪里有卖到达目的地后，记者全程的总车费是14元，但司机到账21元，因此，司机给记者7元，除去之前支付的1元，记者净赚6元，还免费乘了本应支付14元的车。\n",
    "卡尔・斯利姆于2012年加入塔塔汽车公司担任总经理一职，并负责公司在印度及国际市场上除捷豹和路虎以外的业务。这位斯坦福大学的毕业生，曾任通用汽车在中国合资公司的副总裁，上汽通用五菱公司的副总裁以及通用汽车印度公司的总裁。(方赵春)\n",
    "大腕导演不可能每部作品都是你喜欢的东西，如果他一时控制不住情绪，就让他骂吧。他也是人，不是神，人就有自己的脾气。他这次执导春晚，对我也开骂：“老毕，我跟你说了这么长时间，让你走2号位，你非要走1号位，你想跟我较死劲是不是？”这也是骂人。但因为你非常了解他，他也不一定有恶意。\n",
    "招财带什么佛牌不过挣得多，娜姐也花得多。有媒体报道，教练卡洛斯的年薪高达360万元人民币，李娜每年的花费是600多万元。用一个形象的比喻，娜姐每天一睁眼，将近2万元就出去了。\n",
    "“金庸的小说《连城诀》里有一个反派人物‘血刀老祖’，一般的坏人做坏事都是心虚的，但是这个人物却做得心安理得，理直气壮，我遇到的这个的哥就是这样。”王先生向记者描述经过时第一句话便这样说。原来，昨日王先生在搭出租车时，遇到的的哥不仅“拾金而昧”，还“昧”得理直气壮。\n",
    "佛牌绳哪里有卖管中闵进一步指出，台湾出口不能只靠手机、面板等少数产品，而是要将所有优质的产品，千军万马式的输出，打着“台湾制造”的名号，并透过外交争取优惠待遇，将产品推销出去。\n",
    "极速灵猴佛牌作用现在，我们的总书记到餐馆排队买包子，总理拥抱中学生并答应给她回信，都不应被解读为简单的亲民行为，而是在释放明确的政治信号：官员要放下身段，融入百姓之中。\n",
    "此前的1月26日，乌克兰反对派拒绝了总统亚努科维奇提出的让反对派领袖出任政府总理的提议，同时，基辅市的示威者“占领”了司法部。\n",
    "评论回顾1997年县市长选举，民进党在“地方包围中央”策略奏效下，一举拿下台湾12县市过半执政权，首次赢过国民党；2000年的台当局正领导人“大选”，陈水扁趁胜追击再下一城，完成史上首度政党轮替。\n",
    "极速灵猴佛牌作用比亚迪在各地的4S店都没有闭店的情况，放假期间均安排有值班人员，可提供基本的保养和简单的维修服务，除少数4S店外，大部分店的销售部也会留有值班人员。假期的话基本上都是采用内部调休的方式。\n",
    "在百度中搜索“史上最牛个人简历”，电脑屏幕就会被不同的视频链接填满。这些视频的特点是用不同风格展示后期制作技术，再配上画外音和字幕，对作者的个人情况进行介绍。在视频的结尾，作者留下了联系方式，表示自己正在求职，期望找到一份与后期制作或文案策划相关的工作，期待有意向的观看者与他联系、合作。\n",
    "林芳正表示“首席谈判官代理大江博已经在访美”。大江可能正与美国贸易代表办公室(USTR)代理副贸易代表卡特勒等交换意见。\n",
    "“把人撞伤了，总该有个说法吧。”王女士说，哥哥虽然没有生命危险，但肇事者就这样不了了之，于情于理都有些说不过去，“如果有看清车牌号的目击者能够提供有价值线索，我们会给予他(她)一定的资金酬谢。”同时，王女士希望，肇事者能够主动露面，给伤者家属一个合理的说法。(记者徐晓哲/报道)\n",
    "目前，各种财权事权都与城市的行政级别有关，一个县级市和一个地级市的权限差别相当大。要破解这一现象，唯有更多使用市场规律来配置。\n",
    "据中共杭州市委常委、杭州市纪委书记施彩华介绍，1月21日，杭州市委、市政府召开视频会议对开展全市严肃整治“会所中的歪风”暨“三还于民”专项行动进行了专题部署。决定从1月中旬至3月中旬，依据国务院《风景名胜区条例》以及省、市相关条例规定，对全市风景区、公园、名人故居、文化遗址等公共场所开办的各类会所等高档经营场所进行一次全面清理整治。\n",
    "除此之外，入籍还能给艾维拉带来选举权、自由旅行、免于被遣返、不再担惊受怕等各种好处。不过最终，他说入籍的原因并不是为了自己，而只是为了他母亲。\n",
    "'''.split('。')\n",
    "\n",
    "spacy_tok = ChineseTokenizer(tokenizer='spacy')\n",
    "stanza_tok = ChineseTokenizer(tokenizer='stanza')\n",
    "jieba_tok = ChineseTokenizer(tokenizer='jieba')\n",
    "\n",
    "for text in text_samples:\n",
    "    cleaned_text = ChineseTextCleaner(text).clean()\n",
    "    logging.info(f'CLeaned text: {cleaned_text}')\n",
    "\n",
    "    nt, nw, spacy_tokens = spacy_tok.tokenize(cleaned_text)\n",
    "    logging.info(f'spacy tokens: {spacy_tokens}')\n",
    "\n",
    "    nt, nw, stanza_tokens = stanza_tok.tokenize(cleaned_text)\n",
    "    logging.info(f'spacy tokens: {stanza_tokens}')\n",
    "    \n",
    "    nt, nw, jieba_tokens = jieba_tok.tokenize(cleaned_text)\n",
    "    logging.info(f'spacy tokens: {jieba_tokens}')\n",
    "\n",
    "    logging.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inltk\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from spacy.lang.hi import Hindi\n",
    "import nltk\n",
    "import stanza\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Local imports\n",
    "from hi_utils import HindiTextCleaner, HindiTokenizer\n",
    "from logger_config import setup_logging\n",
    "\n",
    "dlogger = setup_logging(log_file='dummy.log')\n",
    "\n",
    "sample_text = '''रिकॉर्ड पांचवीं बार इजरायल की सत्ता संभालेंगे पीएम मोदी के दोस्त बेंजामिन नेतन्याहू! | Israel election: PM Netanyahu appears on track for victory despite tied result - Hindi Oneindia14 min ago #LokSabhaElectionResults2019: 48 साल पहले जो इंदिरा ने किया, वो ही आज मोदी ने कर दिखाया20 min ago Lok Sabha Results 2019 Rajasthan: सीएम गहलोत ने पीएम मोदी पर लगाए कई बड़े आरोप, गड़े मुर्दे भी उखाड़े22 min ago कैराना में इस बार नहीं चला गठबंधन का जादू, भाजपा प्रत्याशी जीत की ओर| Updated: Wednesday, April 10, 2019, 13:00 [IST]तेल अवीव। एक तरफ जहां भारत में लोकसभा चुनावों का आगाज हो रहा है तो वहीं भारत के करीबी देश इजरायल में चुनाव हो चुके हैं। नतीजे आ रहे हैं और सुनकर आपको आश्चर्य होगा कि चुनावी नतीजों में यहां पर टाई हो गया है। लेकिन टाई के बाद भी प्रधानमंत्री बेंजातिन नेतन्याहू की जीत सुनिश्चित लग रही है। नेतन्याहू रिकॉर्ड पांचवीं बार देश के पीएम बनने की ओर बढ़ रहे हैं। हालांकि उनकी लिकुड पार्टी विरोधी ब्लू एंड व्हाइट पार्टी के बराबर ही वोट जीत रही है, इसके बाद भी माना जा रहा है कि नेतन्याहू की जीत तय है।यह भी पढ़ें-केजरीवाल बोले पीएम मोदी की जीत पर पाक में फूटेंगे पटाखे97 प्रतिशत वोटों की गिनती पूरीबेंजामिन की लिकुड पार्टी का मुकाबला बेनी गैंट्ज की पार्टी ब्लू एंड व्हाइट पार्टी से था। अब तक 97 प्रतिशत वोटों की गिनती हो चुकी है। इजरायल की संसद केनेस्सेट में 120 सीटें हैं। नेतन्याहू और गेंट्ज दोनों की पार्टी को 35-35 सीटें अभी तक हासिल हुई हैं। नतीजों में नेतन्याहू, गेंट्ज की तुलना में बेहतर स्थिति में हैं। नेतन्याहू, दूसरी पार्टियों के साथ मिलकर गठबंधन की सरकार बना सकते हैं। वहीं गैंट्ज की पार्टी को दूसरी पार्टियां समर्थन देंगी इस बात की संभावना काफी कम नजर आ रही है। चुनाव के अंतिम नतीजे बुधवार दोपहर तक या शाम तक सामने आएंगे। वहीं सरकार बनने की प्रक्रिया में भी कुछ हफ्तों का समय लग सकता है।दोनों नेताओं ने किया जीत का ऐलानइजरायल के चुनावी नतीजों में काफी टिवस्ट और टर्न आए। नेतन्याहू और गैंट्ज दोनों ने ही खुद को नतीजे आने से पहले ही विजयी बता दिया था। एग्जिट पोल्स में भी दोनों के पास सरकार बनाने का मजबूत दावा बताया जा रहा था। नेतन्याहू ने कहा कि मंगलवार की रात उनके लिए एक विशाल जीत की रात बनी है। इसके साथ ही उन्होंने यह जानकारी भी दी कि उन्होंने राइट विंग पार्टियों के साथ मिलकर सरकार बनाने की कोशिशें भी शुरू कर दी हैं।लगातार 10 वर्षों से शासन कर रहे नेतन्याहूनेतन्याहू के ऐलान को एक घंटे भी नहीं हुए थे कि गैंट्ज ने अपनी जीत का ऐलान कर दिया। उन्होंने कहा, 'चुनावों में कुछ लोग हारते हैं तो कुछ विजेता होते हैं और हम विजेता हैं।' गैंट्ज के ऐलान से बेखबर नेतन्याहू ने यह भी बताया कि वह राष्ट्रपति के सामने अगली सरकार बनाने का प्रस्ताव रखेंगे। 69 वर्षीय नेतन्याहू लगातार 10 वर्षों से देश के पीएम हैं तो वहीं बेनी गैंट्ज देश के सेना प्रमुख रहे चुके हैं। 59 वर्षीय गैंट्ज ने फरवरी 2011 से फरवरी 2015 तक इजरायल डिफेंस फोर्सेज का नेतृत्व किय। दिसंबर 2018 में उन्होंने एक नई राजनीतिक पार्टी शुरू की जिसका नाम इजरायल रिजीलियंस रखा।benjamin netanyahu israel इजरायल प्रधानमंत्रीIsrael election: Prime Minister Benjamin Netanyahu heading leading towards record 5th term as he appears on track for victory despite tied result\n",
    "apsc scam in assam - Guwahati News in Hindi - https://github.com/arrenndajo/Hindi-Text-Analysis-using-NLP/blob/main/Hindi%20Text%20Analysis.ipynb असम में एपीएससी घोटाले की जांच भाजपा सांसद तक पहुंची | Patrika Hindi Newsmp sharma file photo| Publish: Jul, 16 2018 03:18:09 PM (IST) Guwahati, Assam, Indiaघोटाले में अब तक आयोग के पूर्व चैयरमैन, सदस्य समेत कई अधिकारी जेल जा चुके हैंगुवाहाटी। असम लोकसेवा आयोग (एपीएससी) में घोटाले के तार अब भाजपा के सांसद तक जा पहुचे हैं। असम में भाजपा गठबंधन की सरकार है। घोटाले में अब तक आयोग के पूर्व चैयरमैन, सदस्य समेत कई अधिकारी जेल जा चुके हैं। अब मामले की जांच कर रही डिब्रुगढ़ पुलिस ने तेजपुर के भाजपा सांसद राम प्रसाद शर्मा की पुत्री पल्लवी शर्मा समेत 18 और अधिकारियों को समन जारी किया है। इन्हें 18 जुलाई को असम पुलिस की विशेष शाखा के कार्यालय में हस्ताक्षर की फारेंसिक जांच के लिए मौजूद रहने को कहा गया है।चापलूसी राजनीति नहीं करताअपनी प्रतिक्रिया में सांसद शर्मा ने कहा कि मेरे खिलाफ राजनीतिक षडय़ंत्र है। यह पार्टी के अंदर से मेरे खिलाफ षडय़ंत्र है।2 019 के लोकसभा में मुझे तेजपुर से टिकट न मिले इसके लिए मुझे टारगेट किया गया है। मैं 2013 से नागपुर चेहरा दिखाने नहीं गया। मैं मुख्यमंत्री सर्वानंद सोनोवाल, दिल्ली और नागपुर को इस बारे में कोई अनुरोध नहीं करुंगा। मैं चापलूसी राजनीति नहीं करता। इस बार जिन्हें समन दिया गया है उनमें तीन पुलिस अधिकारी,13 प्रशासनिक सेवा के अधिकारी और तीन संबंद्ध सेवा के अधिकारी शामिल हैं।फर्जी रिपोर्ट तैयार करने का आरोपउन्होंने कहा कि फर्जी तरीके से फारेंसिक रिपोर्ट तैयार की गई है। मैंने कभीभी मुख्यमंत्री को जांच धीमी करने को नहीं कहा था। यदि कोई प्रमाणित कर देगा तो मैं राजनीति से संन्यास ले लूंगा। गिरफ्तार असम लोक सेवा आयोग के अध्यक्ष राकेश पाल से मिलने की बात स्वीकारते हुए उन्होंने कहा कि उनकी तरह मैं भी सत्संग में दीक्षित हूं। इसलिए सत्संग विहार में मिला था। यदि मैं दोषी हूं तो जेल जाने को तैयार हूं। उन्होंने कहा कि जांच में पूरा सहयोग करुंगा।कई राजनीतिज्ञों के रिश्तेदार हो चुके गिरफ्तारइससे पहले भी एक पूर्व मंत्री नीलमणि सेन डेका के पुत्र राजश्री सेन डेका, भाजपा की नेता सुमित्रा दले पाटिर की रिश्तेदार गीताली दलै और सुनयना आईदेउ, भाजपा सांसद राजेन गोहाईं का भतीजा भी इस घोटाले में गिरफ्तार हो चुके हैं। इस मामले की जांच कर रहे अतिरिक्त पुलिस अधीक्षक सुरजीत सिंह पानेसर ने कहा कि जिन्हें समन भेजा गया है वे सभी 2016 बेच के अधिकारी हैं। इस घोटाले में पहली गिरफ्तारी अक्तूबर 2016 में हुई थी। अब तक पाल समेत 35 लोगों को गिरफ्तार किया जा चुके हंै। पिछले 2 सालों से जांच चल रही है।यूपी कांग्रेस उपाध्यक्ष ने इस नेता को प्रधानमंत्री बनाने की कर दी अपीलभाजपाई बने बीएलओ, 2019 से पहले शुरू किया ये बड़ा अभियानशिवराज बोले- चुनाव जीतने के लिए अब टोटके करवा रही है कांग्रेसAssam BJP bjp mp Guwahati guwahati news Politicsअसमः अब डायन कहा, तो होगा सश्रम कारावास, राष्ट्रपति ने डायन हत्या रोकथाम कानून को असम में दी मंजूरी\n",
    "'''.split('।')\n",
    "\n",
    "spacy_nlp = Hindi()\n",
    "stanza_nlp = stanza.Pipeline(processors='tokenize', lang='hi')\n",
    "\n",
    "\n",
    "\n",
    "for sentence in sample_text:\n",
    "    cleaned_text = HindiTextCleaner(sentence).clean()\n",
    "\n",
    "    dlogger.info(f'Original: {sentence.strip()}')\n",
    "    dlogger.info(f'cleaned_text: {cleaned_text.strip()}')\n",
    "\n",
    "    res = spacy_nlp(cleaned_text)\n",
    "    spacy_tokens = [word.text for word in res]\n",
    "    dlogger.info(f'spacy tokens: {spacy_tokens}')\n",
    "\n",
    "    doc = stanza_nlp(cleaned_text)\n",
    "    stanza_tokens = [word.text for sentence in doc.sentences for word in sentence.words]\n",
    "    dlogger.info(f'stanza tokens: {stanza_tokens}')\n",
    "\n",
    "    indic_tokens = indic_tokenize.trivial_tokenize(cleaned_text)\n",
    "    dlogger.info(f'indicnlp tokens: {stanza_tokens}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Phonemizer utils\n",
    "# TODO: refacoring\n",
    "\n",
    "# Warnings ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from phonemizer import phonemize\n",
    "from phonemizer.separator import Separator\n",
    "from phonemizer.backend import EspeakBackend\n",
    "\n",
    "# Local imports\n",
    "# from db import LevelDB\n",
    "from ur_utils import UrduTextCleaner, UrduTokenizer\n",
    "from zh_utils import ChineseTextCleaner, ChineseTokenizer\n",
    "\n",
    "# Set up logger configuration\n",
    "log_files: List[str] = ['logs/ur/phonemes.log', 'logs/zh/phonemes.log']\n",
    "logging.basicConfig(\n",
    "    filename='', \n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def generate_phones(text: str, lang: str, backend: str = 'espeak', phone_sep: str = ' ', word_sep: str = '|') -> Any:\n",
    "    # Generate phonemes for words and sentences using the phonemize function\n",
    "\n",
    "    if len(text.split(' ')) > 1:\n",
    "        return [\n",
    "                phonemize(\n",
    "                    word,\n",
    "                    language=lang, \n",
    "                    backend = backend, \n",
    "                    separator=Separator(word=word_sep, phone=phone_sep),\n",
    "                    strip = True,\n",
    "                    preserve_punctuation=False\n",
    "                )    \n",
    "                for word in text.split(' ')\n",
    "        ]\n",
    "    \n",
    "    else:\n",
    "        return phonemize(\n",
    "            text,\n",
    "            language=lang, \n",
    "            backend = backend, \n",
    "            separator=Separator(phone=phone_sep),\n",
    "            strip = True,\n",
    "        )\n",
    "\n",
    "def phonemize_words(word_list: List[str], df: bool = False, utf8_encoding: bool = True) -> Any:\n",
    "\n",
    "    backend: EspeakBackend = EspeakBackend(language='ur')\n",
    "    lex: Dict[str, str] = {word: backend.phonemize([word], separator=Separator(phone=' ', word=None), strip=True)[0] for word in word_list}\n",
    "\n",
    "    if df:\n",
    "        output_df = pd.DataFrame(list(lex.items()), columns = ['Words', 'Phonetic sounds'])\n",
    "        return output_df\n",
    "    \n",
    "    return lex\n",
    "\n",
    "def generate_word_lexicons(language: str, ifile_name: str, ofile_name: str, df: pd.DataFrame = None) -> Any:\n",
    "\n",
    "    # Takes a csv file and generates phones for all the words\n",
    "    backend = EspeakBackend(language=language)\n",
    "    separator = Separator(phone = ' ', word = None)\n",
    "    \n",
    "    input_df: pd.DataFrame = pd.read_csv(ifile_name, encoding = 'utf-8')\n",
    "\n",
    "    # Check if a dataframe is provided as input\n",
    "    if df is not None:    \n",
    "        lexicon: Dict[str, str] = {\n",
    "                word: backend.phonemize([word], separator=separator, strip=True)[0]\n",
    "                for word in df['Word']\n",
    "            }\n",
    "\n",
    "    lexicon: Dict[str, str] = {\n",
    "            word: backend.phonemize([word], separator=separator, strip=True)[0]\n",
    "            for word in input_df['Word']\n",
    "        }\n",
    "\n",
    "    # Output to csv\n",
    "    output_df = pd.DataFrame(list(lexicon.items()), columns = ['Words', 'Phonetic sounds'])\n",
    "    output_df.to_csv(ofile_name, encoding = 'utf-8')\n",
    "\n",
    "    logging.info('file created successfully')\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # example_sentence = 'کی مقدار نوٹ کی گئی جن شرکا کے پیشاب میں'\n",
    "    # l = generate_word_lexicons(language='ur', ifile_name= 'outputs/dummy/words_nltk.csv', ofile_name= 'phones.csv')\n",
    "    # phn = generate_phones(example_sentence, 'ur')\n",
    "    # for word, phone in zip(example_sentence.split(' '), phn):\n",
    "    #     print(word + '-' + phone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
